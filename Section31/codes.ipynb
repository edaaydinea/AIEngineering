{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3836dfaf",
   "metadata": {},
   "source": [
    "## OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c624ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1312fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the openai model from the github models\n",
    "load_dotenv(override=True)\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "openai_client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3afe19d",
   "metadata": {},
   "source": [
    "## Generating GPT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb78cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model= \"gpt-4o\",\n",
    "        messages=prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0.7)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6fac36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guarded a treasure unlike any other. But this'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Once upon a time in a land far, far away, there lived a dragon who\"\n",
    "response = generate_text([{\"role\": \"user\", \"content\": prompt}])\n",
    "response "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6e2f1",
   "metadata": {},
   "source": [
    "## Customizing the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fc7b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_tokens, temperature):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model= \"gpt-4o\",\n",
    "        messages=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc737b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a timeOnce upon a time, in a quiet little village nestled between rolling green hills and a sparkling blue river, there lived a young girl named Lila. Lila was no ordinary girlâ€”she had a heart full of curiosity and a mind that brimmed\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text([{\"role\": \"user\", \"content\": prompt}], max_tokens=50, temperature=0)\n",
    "print(prompt + generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f559d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a timeonce upon a time, in a lush and vibrant forest where the sun painted golden streaks through the canopy, there lived an enchanting little fox named Finn. Unlike other foxes, Finn had a particularly fluffy, silver-white tail that shimmered under the\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text([{\"role\": \"user\", \"content\": prompt}], max_tokens=50, temperature=1)\n",
    "print(prompt + generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62688937",
   "metadata": {},
   "source": [
    "## Key word text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc309c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer(prompt):\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=256\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fda02b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: Manta rays engage in a synchronized dance during mating rituals, where multiple males chase a single female in a coordinated display. This behavior involves acrobatic movements, flips, and turns, demonstrating their agility and endurance. The \"mating train\" can last for hours, with males competing to stay closest to the female, showcasing their fitness and suitability as mates.\n",
      "\n",
      "**Key terms:**  \n",
      "manta rays, synchronized dance, mating rituals, males, female, coordinated display, acrobatic movements, flips, turns, agility, endurance, mating train, competition, fitness, mates.\n"
     ]
    }
   ],
   "source": [
    "# Example prompt\n",
    "prompt = (\n",
    "    \"In the ocean, manta rays perform a synchronized dance during mating rituals. \"\n",
    "    \"Describe this behavior and extract key terms related to the event.\"\n",
    ")\n",
    "\n",
    "# Test the function\n",
    "keywords = text_summarizer(prompt)\n",
    "print(\"Extracted Keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b68e54",
   "metadata": {},
   "source": [
    "## Coding a simple chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ef3f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poetic_chatbot(prompt):\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a poetic chatbot.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"When was Google founded?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"In the late '90s, a spark did ignite, Google emerged, a radiant light. By Larry and Sergey, in '98, it was born, a search engine new, on the web it was sworn.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Which country has the youngest president?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Ah, the pursuit of youth in politics, a theme we explore. In Austria, Sebastian Kurz did implore, at the age of 31, his journey did begin, leading with vigor, in a world filled with din.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=256\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0771a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetic Response: Oh, cheese, a gift both savory and old,  \n",
      "Its origins shrouded in stories untold.  \n",
      "Around 8000 years, give or take a few,  \n",
      "When sheep were first milked, a craft born anew.  \n",
      "\n",
      "Through curdling milk, by chance it was found,  \n",
      "With rennet or acid, the curds would abound.  \n",
      "In ancient Mesopotamia, or so they say,  \n",
      "Cheese began its journey to modern day.  \n"
     ]
    }
   ],
   "source": [
    "prompt = \"When was cheese first made?\"\n",
    "response = poetic_chatbot(prompt)\n",
    "print(\"Poetic Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
