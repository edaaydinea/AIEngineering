{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical representation of text\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section introduces text vectorization, a crucial step in preparing text data for machine learning algorithms. It covers two primary methods: the Bag of Words model and TF-IDF (Term Frequency-Inverse Document Frequency), highlighting their differences and applications.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ”¢ Text vectorization converts text into a numerical format for machine learning.\n",
    "- ğŸ“ The Bag of Words model counts word occurrences, losing context.\n",
    "- âš–ï¸ TF-IDF assesses word importance within documents, considering overall document frequency.\n",
    "- ğŸ“Š Understanding these methods is essential for effective NLP.\n",
    "- ğŸ“š Bag of words is simple and easy to understand.\n",
    "- ğŸ“ˆ TF-IDF captures more context.\n",
    "- ğŸ’¡ The next lesson will cover the specific calculation of TF-IDF.\n",
    "\n",
    "# Bag of Words model\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section demonstrates how to create a Bag of Words model using Python's `CountVectorizer` from the `sklearn` library. It outlines the process of initializing the vectorizer, fitting and transforming the text data, and displaying the resulting matrix as a pandas DataFrame.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ Utilizing `CountVectorizer` from `sklearn.feature_extraction.text` for Bag of Words.\n",
    "- ğŸ¼ Employing pandas for data manipulation and DataFrame creation.\n",
    "- ğŸ”¢ Transforming text into a matrix of token counts.\n",
    "- ğŸ“Š Each row represents a document, and each column represents a word.\n",
    "- 0ï¸âƒ£ and 1ï¸âƒ£ binary representation indicating word presence.\n",
    "- ğŸ“ Simple implementation and easy interpretation of results.\n",
    "- ğŸ“‰ Loss of context is a limitation of the Bag of Words model.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Example text data\n",
    "data = [\n",
    "    \"Most shark attacks occur about ten feet from the beach, since that is where the people are.\",\n",
    "    \"The efficiency with which he paired the socks in the drawer was quite admirable.\",\n",
    "    # ... more sentences\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "count_vec_fit = count_vec.fit_transform(data)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "bag_of_words = pd.DataFrame(count_vec_fit.toarray(), columns=count_vec.get_feature_names_out())\n",
    "\n",
    "# Print the resulting Bag of Words\n",
    "print(bag_of_words)\n",
    "```\n",
    "\n",
    "# TF - IDF\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section explains TF-IDF (Term Frequency-Inverse Document Frequency) as a method for text vectorization, highlighting its ability to retain more context than the Bag of Words model. It details the calculation of term frequency and inverse document frequency and demonstrates how to implement TF-IDF vectorization using scikit-learn's `TfidfVectorizer`.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ“ˆ TF-IDF retains more context compared to the Bag of Words model.\n",
    "- ğŸ§® Term Frequency (TF) measures word occurrence within a document.\n",
    "- âš–ï¸ Inverse Document Frequency (IDF) assesses word importance across all documents.\n",
    "- ğŸ’¡ TF-IDF assigns higher scores to less common, more significant words.\n",
    "- ğŸ Scikit-learn's `TfidfVectorizer` simplifies TF-IDF calculation.\n",
    "- ğŸ“Š The output matrix reflects word importance with varying numerical values.\n",
    "- ğŸ§  Retaining nuanced context aids machine learning model understanding.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example text data (same as before)\n",
    "data = [\n",
    "    \"Most shark attacks occur about ten feet from the beach, since that is where the people are.\",\n",
    "    \"The efficiency with which he paired the socks in the drawer was quite admirable.\",\n",
    "    # ... more sentences\n",
    "]\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_vec_fit = tfidf_vec.fit_transform(data)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_vec_fit.toarray(), columns=tfidf_vec.get_feature_names_out())\n",
    "\n",
    "# Print the resulting TF-IDF DataFrame\n",
    "print(tfidf_df)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
