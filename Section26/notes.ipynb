{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom text classifier\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section introduces the concept of custom text classification using supervised machine learning algorithms, specifically Logistic Regression, Naive Bayes, and Linear Support Vector Machine. It focuses on applying these algorithms to text data, with a recommendation for further learning on algorithm details and hyperparameter tuning.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ¤– Introduction to custom text classification in natural language processing.\n",
    "- ğŸ“Š Supervised machine learning algorithms used for classification.\n",
    "- ğŸ“š Algorithms covered: Logistic Regression, Naive Bayes, and Linear Support Vector Machine.\n",
    "- ğŸ“ Focus on applying these algorithms to text data.\n",
    "- ğŸ’» Practical application of building a custom text classifier using logistic regression.\n",
    "- ğŸ“ Recommendation to explore algorithm details and hyperparameter tuning in 365 Data Science courses.\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section demonstrates how to build a logistic regression model for text classification, using a sample dataset of sentences and their sentiment. It covers data preprocessing, feature extraction using bag-of-words, model training, and evaluation, highlighting the model's initial low accuracy as a baseline for further improvement.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ“ Building a logistic regression model for text classification.\n",
    "- ğŸ“¦ Importing necessary packages: pandas and sklearn.\n",
    "- ğŸ“‚ Using a sample dataset with \"Text\" and \"Sentiment\" columns.\n",
    "- ğŸ”€ Shuffling and preparing the data for training and testing.\n",
    "- ğŸ”¢ Text vectorization using CountVectorizer (bag-of-words).\n",
    "- ğŸ“Š Splitting data into training and testing sets.\n",
    "- ğŸš‚ Training the logistic regression model.\n",
    "- ğŸ“‰ Evaluating model performance using accuracy score and classification report.\n",
    "- ğŸ“ˆ Establishing the model as a baseline for future improvements.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "Python\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Sample dataset (replace with your actual data)\n",
    "data = pd.DataFrame({'Text': ['This is good', 'This is bad'], 'Sentiment': [1, 0]})\n",
    "\n",
    "# Shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Prepare X and y\n",
    "X = data['Text']\n",
    "y = data['Sentiment']\n",
    "\n",
    "# Vectorization (bag of words)\n",
    "count_vec = CountVectorizer()\n",
    "X_counts = count_vec.fit_transform(X)\n",
    "bag_of_words = pd.DataFrame(X_counts.toarray(), columns=count_vec.get_feature_names_out())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred_LR = LR.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_LR)\n",
    "report = classification_report(y_test, y_pred_LR)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "```\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section explores improving text classification accuracy using the Naive Bayes algorithm. It demonstrates importing the MultinomialNB module, training the model, and evaluating its performance, showing a slight improvement in accuracy compared to the logistic regression baseline.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ§ª Implementing the Naive Bayes algorithm for text classification.\n",
    "- ğŸ“¦ Importing the MultinomialNB module from sklearn.\n",
    "- ğŸš‚ Training the Naive Bayes model with training data.\n",
    "- ğŸ“Š Evaluating the model's accuracy and classification report.\n",
    "- ğŸ“ˆ Observing a slight improvement in accuracy compared to logistic regression.\n",
    "- ğŸ“ Acknowledging the need for further improvement with more complex models.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Naive Bayes model\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "y_pred_NB = NB.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_NB)\n",
    "report_nb = classification_report(y_test, y_pred_NB)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb}\")\n",
    "print(f\"Naive Bayes Classification Report:\\n{report_nb}\")\n",
    "```\n",
    "\n",
    "# Linear support vector machine\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section explores the Linear Support Vector Machine (SVM) algorithm for text classification, using the SGDClassifier from scikit-learn. It covers importing the necessary module, training the SVM model, making predictions, and evaluating the accuracy, showing an improvement over previous models but still indicating a need for further optimization.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ¤– Implementing the Linear Support Vector Machine (SVM) algorithm.\n",
    "- ğŸ“¦ Importing the SGDClassifier from sklearn.linear_model.\n",
    "- ğŸš‚ Training the SVM model with training data.\n",
    "- ğŸ“Š Evaluating the model's accuracy.\n",
    "- ğŸ“ˆ Observing an improvement in accuracy compared to previous models.\n",
    "- ğŸ“ Acknowledging the need for data refinement and potential data augmentation for better performance.\n",
    "- ğŸ”„ Emphasizing the iterative nature of machine learning projects and the importance of refining the data and approach.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# SVM model\n",
    "SVM = SGDClassifier()\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred_SVM = SVM.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_SVM)\n",
    "\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
