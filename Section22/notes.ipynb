{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Tagging\n",
    "\n",
    "### Summary\n",
    "\n",
    "This video introduces two text tagging methods: Parts of Speech (POS) tagging, which labels tokens as verbs, nouns, etc., and Named Entity Recognition (NER), which identifies entities like people and places. These techniques aid in text exploration and feature creation for machine learning.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üè∑Ô∏è Parts of Speech (POS) tagging labels each token with its grammatical role (verb, noun, adjective).\n",
    "- üìç Named Entity Recognition (NER) identifies and extracts named entities like people, places, and organizations.\n",
    "- üîç These tagging methods are useful for exploring and understanding text data.\n",
    "- üìä Tagging can also be used to create additional features for machine learning algorithms.\n",
    "- üìà These methods can be used for standalone analysis.\n",
    "- üêç The next lessons will cover how to implement these methods in Python.\n",
    "\n",
    "# Parts of Speech (POS) tagging\n",
    "\n",
    "### Summary\n",
    "\n",
    "This lesson demonstrates Parts of Speech (POS) tagging using Spacy and Pandas in Python. It involves loading a Spacy model, processing text (Jane Austen's Emma), extracting tokens and their POS tags into a DataFrame, and analyzing the frequency of tokens and tags.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üêç Uses Spacy and Pandas libraries for POS tagging.\n",
    "- üìñ Processes text from Jane Austen's Emma.\n",
    "- üìä Creates a Pandas DataFrame to store tokens and POS tags.\n",
    "- üî¢ Calculates and displays the most common tokens and their POS tags.\n",
    "- üìà Analyzes the frequency of different POS tags in the text.\n",
    "- üîç Filters and displays the most common nouns and adjectives.\n",
    "- üë©‚Äçüíª Demonstrates how to extract and analyze POS tag information for text analysis.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "Python\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the text (Jane Austen's Emma)\n",
    "text = \"emma text here\" # Replace with actual text\n",
    "\n",
    "# Create a Spacy document\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract tokens and POS tags into a DataFrame\n",
    "pos_df = pd.DataFrame(columns=['token', 'pos_tag'])\n",
    "for token in doc:\n",
    "    pos_df = pd.concat([pos_df, pd.DataFrame([{'token': token.text, 'pos_tag': token.pos_}])], ignore_index=True)\n",
    "\n",
    "# Analyze most common tokens and tags\n",
    "pos_df_counts = pos_df.groupby(['token', 'pos_tag']).size().reset_index(name='counts').sort_values('counts', ascending=False)\n",
    "print(pos_df_counts.head(10))\n",
    "\n",
    "# Analyze POS tag frequency\n",
    "pos_df_pos_counts = pos_df.groupby('pos_tag')['token'].count().sort_values(ascending=False)\n",
    "print(pos_df_pos_counts.head())\n",
    "\n",
    "# Filter and display most common nouns\n",
    "nouns = pos_df_counts[pos_df_counts['pos_tag'] == 'NOUN'].head(10)\n",
    "print(nouns)\n",
    "\n",
    "# Filter and display most common adjectives\n",
    "adjectives = pos_df_counts[pos_df_counts['pos_tag'] == 'ADJ'].head(10)\n",
    "print(adjectives)\n",
    "```\n",
    "\n",
    "# Named Entity Recognition (NER)\n",
    "\n",
    "### Summary\n",
    "\n",
    "This lesson covers Named Entity Recognition (NER) using Spacy in Python. It demonstrates how to identify and visualize named entities in text, highlighting the impact of text cleaning on NER results. The lesson emphasizes the importance of considering the timing of text cleaning in relation to NER.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üì¶ Uses Spacy and Displacy libraries for NER and visualization.\n",
    "- üìÑ Processes text from the Google Wikipedia page.\n",
    "- üè∑Ô∏è Identifies and labels named entities like dates, people, and organizations.\n",
    "- üé® Visualizes named entities using Displacy's render function.\n",
    "- üßπ Shows how text cleaning (removing punctuation, lowercasing) affects NER results.\n",
    "- ‚è∞ Emphasizes the importance of timing text cleaning in relation to NER.\n",
    "- üßê Encourages experimentation with pre-processing to optimize NER results.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import re\n",
    "\n",
    "# Load the Spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text from Google Wikipedia page\n",
    "google_text = \"Google, LLC is an American multinational technology company that focuses on search engine technology, online advertising, cloud computing, computer software, quantum computing, e-commerce, artificial intelligence, and consumer electronics. It was founded in September 4, 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\"\n",
    "\n",
    "# Create a Spacy document\n",
    "doc = nlp(google_text)\n",
    "\n",
    "# Print entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Visualize entities using Displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "# Clean the text (remove punctuation, lowercase)\n",
    "google_text_clean = re.sub(r'[^\\w\\s]', '', google_text).lower()\n",
    "\n",
    "# Create a Spacy document from the cleaned text\n",
    "doc_clean = nlp(google_text_clean)\n",
    "\n",
    "# Print entities and their labels from the cleaned text\n",
    "for ent in doc_clean.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Visualize entities from the cleaned text\n",
    "displacy.render(doc_clean, style=\"ent\", jupyter=True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
