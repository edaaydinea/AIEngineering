{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1063d54a",
   "metadata": {},
   "source": [
    "# RunnablePassthrough with Additional Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df900c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727890ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human: \n",
    "{question}\n",
    "\n",
    "AI:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d343548",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(model = 'llama3.2',\n",
    "                  temperature = 0,\n",
    "                  num_predict=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577021c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb1ca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'd be happy to provide more information about the fascinating cardiovascular system of octopuses! The three hearts in an octopus are indeed a remarkable feature that sets them apart from other animals. Two of these hearts, known as branchial hearts, pump blood directly to the octopus's gills, where oxygen is absorbed into the bloodstream. These two hearts are located on either side of the esophagus and are responsible for supplying oxygenated blood to the gills.\\n\\nThe third heart, also known\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'message_log':'''The AI provides an interesting fact about octopuses, stating that they have three hearts. \n",
    "Two hearts pump blood to the gills, while the third heart pumps it to the rest of the body.''', \n",
    "              'question':\"Can you elaborate a bit more on this fact?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc451d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eda AYDIN\\AppData\\Local\\Temp\\ipykernel_19104\\129871963.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = ConversationSummaryMemory(llm = ChatOllama(model=\"llama3.2\"), memory_key = 'message_log')\n"
     ]
    }
   ],
   "source": [
    "chat_memory = ConversationSummaryMemory(llm = ChatOllama(model=\"llama3.2\"), memory_key = 'message_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd23c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': ''}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25358811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Can you give me an interesting fact I probably didn't know about?\",\n",
       " 'message_log': {'message_log': ''}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough.assign(message_log = chat_memory.load_memory_variables).invoke(\n",
    "    {'question':\"Can you give me an interesting fact I probably didn't know about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3369902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'first_letter': 'h', 'second_letter': 'i'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough.assign(first_letter = lambda x: list(x['input'])[0], \n",
    "                           second_letter = lambda x: list(x['input'])[1]\n",
    "                          ).invoke({'input':'hi'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
