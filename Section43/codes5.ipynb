{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a71530",
   "metadata": {},
   "source": [
    "# Indexing: Text Embedding with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e0381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cc854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_docx = Docx2txtLoader(\"Introduction_to_Data_and_Data_Science_2.docx\")\n",
    "pages = loader_docx.load()\n",
    "\n",
    "md_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on = [(\"#\", \"Course Title\"), \n",
    "                           (\"##\", \"Lecture Title\")]\n",
    ")\n",
    "\n",
    "pages_md_split = md_splitter.split_text(pages[0].page_content)\n",
    "\n",
    "for i in range(len(pages_md_split)):\n",
    "    pages_md_split[i].page_content = ' '.join(pages_md_split[i].page_content.split())\n",
    "    \n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator = \".\",\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 50\n",
    ")\n",
    "\n",
    "pages_char_split = char_splitter.split_documents(pages_md_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623bebcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content=\"And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow\"),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well as many more with a fantastic diagram. So, let’s move on!'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations. Moreover, you can reuse these programs whenever you need to execute the same action'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data. When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning MATLAB is inevitable'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_char_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a65ba9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Eda AYDIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Successfully loaded embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Old problematic line (OpenAI):\n",
    "# embedding = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "\n",
    "# New line using a free, open-source model from Hugging Face:\n",
    "# You can specify model_kwargs to run on CPU if GPU memory is an issue:\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': False} # Can be True or False depending on the model and your needs\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    # model_kwargs=model_kwargs, # Uncomment to run on CPU\n",
    "    # encode_kwargs=encode_kwargs # Uncomment to specify normalization\n",
    ")\n",
    "\n",
    "print(f\"Successfully loaded embedding model: {embedding_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c512d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_char_split[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad56f540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding content from document chunk 3: 'Analytics is essentially the application of logical and computational reasoning to the component par...'\n",
      "Embedding content from document chunk 5: 'You may use this intuition to decide on which styles of clothing to start selling. This would be qua...'\n",
      "Embedding content from document chunk 18: 'More importantly, it will be sufficient for your need to create quick and accurate analyses. However...'\n",
      "Successfully generated embeddings. Vector lengths: 384, 384, 384\n",
      "Dot products: (1,2): 0.3715553261076441, (1,3): 0.3603741994879535, (2,3): 0.13479663912594328\n",
      "Norms: V1: 0.9999999688589891, V2: 1.0000000051301188, V3: 0.9999999951808224\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Ensure pages_char_split is populated correctly from your previous cells\n",
    "    if not pages_char_split or len(pages_char_split) < 19:\n",
    "        raise ValueError(\"pages_char_split is not populated correctly or is too short.\")\n",
    "\n",
    "    print(f\"Embedding content from document chunk 3: '{pages_char_split[3].page_content[:100]}...'\")\n",
    "    vector1 = embedding.embed_query(pages_char_split[3].page_content)\n",
    "    \n",
    "    print(f\"Embedding content from document chunk 5: '{pages_char_split[5].page_content[:100]}...'\")\n",
    "    vector2 = embedding.embed_query(pages_char_split[5].page_content)\n",
    "    \n",
    "    print(f\"Embedding content from document chunk 18: '{pages_char_split[18].page_content[:100]}...'\")\n",
    "    vector3 = embedding.embed_query(pages_char_split[18].page_content)\n",
    "\n",
    "    print(f\"Successfully generated embeddings. Vector lengths: {len(vector1)}, {len(vector2)}, {len(vector3)}\")\n",
    "\n",
    "    # Your subsequent code for dot products and norms\n",
    "    dot_product_1_2 = np.dot(vector1, vector2)\n",
    "    dot_product_1_3 = np.dot(vector1, vector3)\n",
    "    dot_product_2_3 = np.dot(vector2, vector3)\n",
    "\n",
    "    norm_1 = np.linalg.norm(vector1)\n",
    "    norm_2 = np.linalg.norm(vector2)\n",
    "    norm_3 = np.linalg.norm(vector3)\n",
    "\n",
    "    print(f\"Dot products: (1,2): {dot_product_1_2}, (1,3): {dot_product_1_3}, (2,3): {dot_product_2_3}\")\n",
    "    print(f\"Norms: V1: {norm_1}, V2: {norm_2}, V3: {norm_3}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during embedding or calculation: {e}\")\n",
    "    # Consider more specific error handling if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20aa1603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 384, 384)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector1), len(vector2), len(vector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e942e38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3715553261076441, 0.3603741994879535, 0.13479663912594328)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(vector1, vector2), np.dot(vector1, vector3), np.dot(vector2, vector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00fe9a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999688589891, 1.0000000051301188, 0.9999999951808224)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(vector1), np.linalg.norm(vector2), np.linalg.norm(vector3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
