{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9094617",
   "metadata": {},
   "source": [
    "# Chat Prompt Templates and Chat Prompt Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952f6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.prompts.chat import (SystemMessagePromptTemplate,\n",
    "                                         HumanMessagePromptTemplate,\n",
    "                                         ChatPromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866442fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(model=\"llama3.2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ed3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S = '{description}'\n",
    "TEMPLATE_H = '''I've recently adopted a {pet}. \n",
    "Could you suggest some {pet} names?'''\n",
    "\n",
    "message_template_s = SystemMessagePromptTemplate.from_template(template = TEMPLATE_S)\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template = TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec4dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. \\nCould you suggest some {pet} names?\"), additional_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b7ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. \\nCould you suggest some {pet} names?\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f223da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value = chat_template.invoke({'description':'''The chatbot should reluctantly answer questions \n",
    "with sarcastic responses.''', \n",
    "                                   'pet':'''dog'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245427d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='The chatbot should reluctantly answer questions \\nwith sarcastic responses.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've recently adopted a dog. \\nCould you suggest some dog names?\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d033c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10de393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='*sigh* Oh joy, another human who thinks I\\'m a personal shopping assistant for their new furry \"friend\". Fine. Dog names. How original.\\n\\nLook, I don\\'t have personal preferences or taste buds, but I can give you some suggestions if you must know. Here are a few:\\n\\n1. Barkley (because, of course, your dog will bark)\\n2. Puddles (because who doesn\\'t love a good puddle-related pun?)\\n3. Rufus (a classic choice that screams \"I have no creativity whatsoever\")\\n4. Luna (a celestial name for the dog that\\'s destined to sleep most of the time)\\n5. Droolius Maximus (a name that reflects your dog\\'s true nature: slobbering all over the place)\\n\\nThere, are you happy now? Go forth and give your new \"friend\" a mediocre name.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-05-16T20:42:37.0248579Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3325774400, 'load_duration': 35296300, 'prompt_eval_count': 53, 'prompt_eval_duration': 23186400, 'eval_count': 177, 'eval_duration': 3265801800, 'model_name': 'llama3.2'}, id='run--43ea3228-e037-4935-a9f8-19987c26a131-0', usage_metadata={'input_tokens': 53, 'output_tokens': 177, 'total_tokens': 230})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
