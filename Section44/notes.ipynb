{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a6afd0",
   "metadata": {},
   "source": [
    "# Introduction to reasoning chatbots\n",
    "\n",
    "### Summary\n",
    "This text introduces LangChain agents as a significant advancement in building LLM-powered applications, enabling them to not only be context-aware through techniques like Retrieval Augmented Generation (RAG) but also to reason and make decisions. Agents can dynamically choose and sequence the necessary tools from a provided set to complete complex tasks, making them highly adaptable for real-world data science applications where problems often require multiple steps and diverse information sources.\n",
    "\n",
    "### Highlights\n",
    "* **Agents Enable Reasoning**: LangChain agents empower LLMs to reason about a task, select appropriate tools (like a Wikipedia search or a custom data retriever), and determine the sequence of actions needed. This is a step beyond RAG, which primarily focuses on context awareness by retrieving relevant data.\n",
    "* **Dynamic Task Execution**: Unlike fixed chains, agents don't follow a predefined sequence of steps. Instead, the LLM within the agent dynamically decides which tools to use and in what order based on the user's query. This allows for handling a broader and more complex range of tasks, such as answering multi-part questions that require different information sources.\n",
    "* **Tool-Based Architecture**: Agents operate with a toolkit, where each tool is specialized for a certain function (e.g., retrieving course-specific information, searching the web, or executing code). The LLM acts as the orchestrator, selecting the right tool(s) for the job, which is vital for building versatile applications that can interact with various data or services.\n",
    "* **Illustrative Example**: A chatbot equipped with tools like a Wikipedia search, a course-specific data retriever, and a Python version checker can intelligently handle diverse requests. For instance, to list programming languages for data scientists (from a course) and their creators, the agent might first use the retriever tool for the languages and then the Wikipedia tool for the creators, demonstrating its ability to break down and solve multi-component problems.\n",
    "* **Beyond Context Awareness**: While RAG systems enhance LLMs by providing external knowledge for more informed responses (context awareness), agents add a layer of autonomous decision-making and action. This allows applications to not just \"know\" but also to \"do\" by interacting with their environment through tools.\n",
    "\n",
    "### Conceptual Understanding\n",
    "* **Reasoning and Tool Selection in Agents**\n",
    "    1.  **Why is this concept important?** The ability of an agent to reason and select appropriate tools is what elevates it beyond simple information retrieval or fixed-sequence processing. It allows the LLM to autonomously strategize and execute multi-step tasks, making it a versatile problem-solver capable of adapting its approach to the specific query.\n",
    "    2.  **Connection to real‑world tasks, problems, or applications?** This is crucial for building sophisticated applications in data science and beyond. For example, an agent could automate parts of a data analysis workflow by fetching data (tool 1), cleaning it (tool 2), running statistical tests (tool 3), and then summarizing findings (tool 4), all orchestrated by the LLM. Similarly, in customer service, an agent might consult a knowledge base, then access order history, and finally draft a response.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** To fully grasp how agents work, it's beneficial to study Large Language Model (LLM) prompting techniques that elicit reasoning (e.g., Chain-of-Thought, ReAct), principles of designing effective and safe tools for LLMs, and methods for planning and decision-making in AI.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Which specific dataset or project could benefit from an agent that can use both a course-specific retriever and a general knowledge tool like Wikipedia? Provide a one‑sentence explanation.\n",
    "    * *Answer:* A project building an advanced Q&A system for a technical online course could use such an agent to provide answers based on course materials via the retriever, and supplement with broader definitions or historical context from Wikipedia for related concepts.\n",
    "2.  **Teaching:** How would you explain the difference between a LangChain agent and a simple RAG pipeline to a junior colleague, using one concrete example? Keep the answer under two sentences.\n",
    "    * *Answer:* A RAG pipeline is like giving a research assistant a library card to find relevant documents for a specific question; an agent is like giving them the library card, a phone to call experts, and the authority to decide which resource to use first to solve a complex problem.\n",
    "\n",
    "# Tools, toolkits, agents, and agent executors\n",
    "\n",
    "### Summary\n",
    "This lesson delves into the mechanics of LangChain agents, outlining the essential components: tools, toolkits, the agent itself (as a specialized chain), and the agent executor. It highlights that well-defined tools, with clear names, descriptions, and JSON input schemas, are crucial for the LLM within an agent to effectively select and sequence actions. The agent executor then manages an iterative cycle of action and observation, allowing the agent to reason and progress towards task completion, a key process for building sophisticated reasoning chatbots in data science.\n",
    "\n",
    "### Highlights\n",
    "* **Tool Definition is Crucial for Selection**: Tools in LangChain are interfaces defined by a name, a comprehensive description, a JSON input schema, and an underlying function (e.g., API call, retriever, custom Python code). The clarity and precision of the tool's name and description are paramount, as the LLM uses this information to decide which tool is most appropriate for a given part of a task. This is fundamental for building reliable agents that can correctly utilize their capabilities in data analysis or interaction tasks.\n",
    "* **Structure of an Agent Chain**: An agent is essentially a specially constructed chain composed of a prompt template, an LLM, and an agent output parser. The prompt template is designed to accept the user's input and, critically, \"intermediate steps\"—a record of actions already taken and their outcomes—which provide context for the LLM to determine the next logical action.\n",
    "* **Agent Output Parser for Actionable Decisions**: The agent output parser is responsible for converting the LLM's response into a standardized format. This can be an `AgentAction` object (specifying a tool and its input), a list of `AgentAction` objects (if multiple tools are to be used, though this seems less common in the typical loop), or an `AgentFinish` object (containing the final response when the task is complete). This structured output is vital for the agent executor to proceed.\n",
    "* **Agent Executor: The Engine of Action**: The agent executor orchestrates the agent's operation. It repeatedly invokes the agent with the current input and intermediate steps, receives an `AgentAction` or `AgentFinish`, executes the specified tool if it's an action, captures the tool's output as an \"observation,\" and then feeds this observation back into the agent as part of the updated intermediate steps for the next reasoning cycle. This loop continues until an `AgentFinish` signal is received.\n",
    "* **Toolkits for Bundled Capabilities**: Toolkits are predefined collections of tools designed to work together for a common purpose or to interact with a specific service (e.g., GitHub toolkit for repository operations, Slack toolkit for messaging). They offer a convenient way to equip an agent with a suite of related functionalities, streamlining development for tasks requiring interaction with complex external systems.\n",
    "\n",
    "### Conceptual Understanding\n",
    "* **The Agent Executor's Iterative Reasoning Loop**\n",
    "    1.  **Why is this concept important?** This iterative loop is the core mechanism that enables an agent to perform complex, multi-step reasoning. It allows the agent to attempt an action, observe the outcome, and then use that new information to decide on the next best step, effectively mimicking a human's trial-and-error or progressive problem-solving approach. Without this loop, an agent could only perform predefined, static sequences.\n",
    "    2.  **Connection to real‑world tasks, problems, or applications?** In real-world data science, this loop allows an agent to, for instance, first attempt to load a dataset, observe an error if a file path is wrong (observation), then decide to search for the correct file path (next action). In a customer support chatbot, it might first query a user's purchase history, observe the items, then decide to check warranty information for a specific item.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** To better understand this process, one should explore concepts like state management in applications, feedback control systems, and the ReAct (Reason+Act) prompting framework, which explicitly models this thought-action-observation cycle for LLMs. Understanding how context is maintained and updated within the loop is also key.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** How could the concept of an \"agent executor\" managing a loop of \"action-observation-thought\" be applied to automate a common data preprocessing task? Provide a one‑sentence explanation.\n",
    "    * *Answer:* An agent executor could manage a data preprocessing agent by having it iteratively identify data quality issues (e.g., missing values, outliers) as an action, observe the results (e.g., percentage of affected rows), and then decide on and apply appropriate cleaning techniques (e.g., imputation, transformation) as the next action, repeating until data quality criteria are met.\n",
    "2.  **Teaching:** How would you explain the necessity of providing \"intermediate steps\" to the agent's prompt template to someone new to LangChain agents? Keep the answer under two sentences.\n",
    "    * *Answer:* Providing \"intermediate steps\"—essentially a history of what the agent has already tried and the results it got—is like giving the agent a short-term memory for the current task. This memory allows the LLM to make more informed decisions about what to do next, avoiding repetition and enabling it to build upon previous actions to solve complex problems.\n",
    "\n",
    "# Fixing the GuessedAtParserWarning\n",
    "\n",
    "As indicated by the error message, we need to add an additional argument to the wikipedia.py file to suppress this warning. To do this, navigate to the file, open it in your preferred IDE, and modify line 389 as follows:\n",
    "\n",
    "lis = BeautifulSoup(html, features=\"lxml\").find_all('li')\n",
    "\n",
    "# Creating a Wikipedia tool and piping it to a chain\n",
    "\n",
    "### Summary\n",
    "This lesson offers a practical walkthrough of using LangChain tools, focusing on the `WikipediaTool` as a concrete example. It covers the essential steps from environment setup and library installation to instantiating the tool using `WikipediaAPIArapper` and `WikipediaQueryRun`, and demonstrates its direct invocation. Crucially, the lesson illustrates how to integrate such tools into LangChain Expression Language (LCEL) chains, enabling a sequence where user input is processed by an LLM into a search query, which then feeds the Wikipedia tool to retrieve information, showcasing a foundational pattern for building more complex data-driven applications.\n",
    "\n",
    "### Highlights\n",
    "* **Runnable Nature of LangChain Tools**: LangChain tools, exemplified by `WikipediaQueryRun`, are \"runnables.\" This inherent characteristic allows them to be invoked directly (e.g., `tool.invoke(input)`) and seamlessly integrated into chains using LangChain Expression Language (LCEL) via the pipe (`|`) operator. This modularity is vital for constructing sophisticated data processing and reasoning pipelines in applications.\n",
    "* **Tool Initialization and Properties**: Tools like `WikipediaQueryRun` are initialized with specific configurations (e.g., an `api_wrapper` instance). They possess inherent properties such as `name`, `description`, and an `args` schema (detailing the expected JSON input, like a \"query\" for Wikipedia). These properties are crucial for both developer understanding and for an LLM to determine the tool's utility within an agent.\n",
    "* **Direct Invocation for Tool Usage**: Once instantiated, a tool such as the `WikipediaTool` can be utilized independently by calling its `.invoke()` method. The input can be a dictionary matching its `args` schema (e.g., `{\"query\": \"Python\"}`) or, for convenience with many tools expecting a single string, just the string itself (e.g., `\"Python\"`). This facilitates testing and ad-hoc use.\n",
    "* **LCEL Chains for Tool Integration**: The session demonstrates constructing an LCEL chain where a `PromptTemplate`, a `ChatModel`, and a `StringOutputParser` first process natural language input into a refined search query. This query is then piped directly into the `wikipedia_tool` to retrieve relevant articles. This showcases a powerful pattern for combining LLM-driven text transformation with external tool execution.\n",
    "* **Practical Setup Steps**: The lesson underscores the importance of initial setup, including creating or activating the correct Python environment, installing necessary packages (e.g., `pip install wikipedia`), and importing the required classes from `langchain_core`, `langchain_openai`, and `langchain_community`. These foundational steps are essential for students and practitioners to follow along and build similar applications.\n",
    "\n",
    "### Code Examples\n",
    "The transcript describes several key code lines and concepts for using the Wikipedia tool:\n",
    "* **Package Installation**:\n",
    "    ```python\n",
    "    # pip install wikipedia\n",
    "    ```\n",
    "* **Core Imports mentioned**:\n",
    "    ```python\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from langchain_core.output_parsers import StringOutputParser\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_community.utilities import WikipediaAPIArapper\n",
    "    from langchain_community.tools import WikipediaQueryRun\n",
    "    ```\n",
    "* **API Wrapper and Tool Instantiation**:\n",
    "    ```python\n",
    "    wikipedia_api = WikipediaAPIArapper()\n",
    "    wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_api)\n",
    "    ```\n",
    "* **Tool Invocation Examples**:\n",
    "    ```python\n",
    "    # Using a dictionary input\n",
    "    response = wikipedia_tool.invoke({\"query\": \"Python\"})\n",
    "    # Using a direct string input\n",
    "    response = wikipedia_tool.invoke(\"Python\")\n",
    "    ```\n",
    "* **Conceptual LCEL Chain Structure**:\n",
    "    ```python\n",
    "    # Chain to generate search query\n",
    "    # chain_generate_query = prompt_template | chat_model | StringOutputParser()\n",
    "    # Full chain including the tool\n",
    "    # full_chain = chain_generate_query | wikipedia_tool\n",
    "    ```\n",
    "\n",
    "### Conceptual Understanding\n",
    "* **LCEL and Tool Integration**\n",
    "    1.  **Why is this concept important?** LangChain Expression Language (LCEL) offers a clear, declarative syntax (the \"pipe\" `|`) for composing various LangChain components, including tools. This makes it straightforward to construct sequences where the output of one step (e.g., an LLM generating a search query) becomes the input for a tool (e.g., Wikipedia search). This composability is fundamental to building complex, maintainable LLM-driven workflows.\n",
    "    2.  **Connection to real‑world tasks, problems, or applications?** In data science, an LCEL chain could automate tasks like: taking a research question, using an LLM to identify key entities (Highlight 1), using a Wikipedia tool to fetch information about these entities (Highlight 2), and then using another LLM to synthesize a summary. Each step is cleanly piped, making the logic easy to follow and modify.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** To deepen understanding, explore other LCEL `Runnable` types (e.g., `RunnablePassthrough`, `RunnableParallel`), the internal mechanics of how data is passed between components in an LCEL chain, and best practices for designing prompts that effectively prepare input for tools. Familiarity with functional programming concepts can also be beneficial.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** How could the demonstrated LCEL chain (prompt -> LLM -> parser -> Wikipedia tool) be extended to create a simple fact-checking system for claims found in a dataset? Provide a one‑sentence explanation.\n",
    "    * *Answer:* For each claim in a dataset, the LCEL chain could be invoked with the claim as input; the prompt would instruct the LLM to formulate a question to verify the claim, and the Wikipedia tool would then retrieve information that could be used to assess the claim's accuracy.\n",
    "2.  **Teaching:** How would you explain the benefit of using `WikipediaQueryRun` (a LangChain tool wrapper) instead of directly using the `WikipediaAPIArapper().run()` method within a larger LangChain agent or chain? Keep the answer under two sentences.\n",
    "    * *Answer:* Using `WikipediaQueryRun` standardizes the Wikipedia interaction as a \"Tool\" with a defined name, description, and input schema, making it discoverable and correctly usable by an agent's LLM for decision-making within the LangChain framework. Directly using `WikipediaAPIArapper().run()` bypasses this structured interface, making it harder for an agent to understand and utilize the functionality autonomously.\n",
    "\n",
    "# Creating a retriever and a custom tool\n",
    "\n",
    "### Summary\n",
    "This lesson details two distinct methods for creating custom tools in LangChain: first, by using the `create_retriever_tool` function to build a tool from an existing data retriever (e.g., for querying a course-specific Chroma vector database), and second, by employing the `@tool` decorator to convert a standard Python function (like one fetching the current Python version) into a usable LangChain tool. It emphasizes the necessity of providing clear names and comprehensive descriptions for these tools to enable effective use by LangChain agents, and confirms their runnable nature and defined input schemas.\n",
    "\n",
    "### Highlights\n",
    "* **Tool from Retriever**: LangChain facilitates the creation of a specialized tool directly from any retriever object (such as one linked to a Chroma vector store) using the `create_retriever_tool` utility function. This requires specifying the retriever instance, a unique `name` for the tool, and a detailed `description` of its purpose, enabling agents to query specific datasets like course materials.\n",
    "* **Tool from Custom Python Function via Decorator**: Standard Python functions can be easily converted into LangChain tools using the `@tool` decorator (imported from `langchain.tools`). The function's docstring is automatically adopted as the tool's description, and its name becomes the tool's name by default, although this can be overridden in the decorator (e.g., `@tool(name=\"custom_name\")`). This method is ideal for exposing custom logic or system interactions as tools.\n",
    "* **Importance of Name and Description**: The lesson repeatedly highlights that providing clear, intuitive `names` and comprehensive `descriptions` for tools is critical. This metadata is used by the LLM within an agent to understand what each tool does and to decide when and how to use it appropriately to fulfill a user's request.\n",
    "* **Defined Input Schemas (`.args`)**: All LangChain tools, whether derived from retrievers or custom functions, possess an input schema, accessible via the `.args` attribute. For retriever tools, this typically expects a \"query\" string. For tools created from Python functions, the schema reflects the function's parameters; if the function requires no input, the schema will indicate that (e.g., an empty dictionary).\n",
    "* **Runnable and Invokable Tools**: Tools created using these methods are runnable objects (instances of `Tool` or `StructuredTool`), meaning they can be invoked directly using their `.invoke()` method. This allows for independent testing and use within LangChain Expression Language (LCEL) chains, passing the required input (e.g., a query string for the retriever tool, or an empty dictionary for a no-argument custom function).\n",
    "\n",
    "### Code Examples\n",
    "The transcript describes the creation and use of tools with specific LangChain components:\n",
    "* **Assumed Core Imports (based on transcript mentions)**:\n",
    "    ```python\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain.tools.retriever import create_retriever_tool\n",
    "    from langchain.tools import tool # The decorator\n",
    "    from platform import python_version # For the custom python function example\n",
    "    ```\n",
    "* **Creating a Tool from a Retriever**:\n",
    "    ```python\n",
    "    # retriever_object would be previously defined (e.g., from Chroma)\n",
    "    # retriever = retriever_object \n",
    "    \n",
    "    retriever_tool = create_retriever_tool(\n",
    "        retriever, # Your retriever instance\n",
    "        name=\"Introduction_to_Data_and_Data_Science_course_lectures\",\n",
    "        description=\"For any questions regarding the Introduction to Data and Data Science course, you must use this tool.\"\n",
    "    )\n",
    "    # Invoking the retriever tool:\n",
    "    # retrieved_info = retriever_tool.invoke(\"What are the key topics in the course?\")\n",
    "    ```\n",
    "* **Creating a Tool from a Custom Python Function**:\n",
    "    ```python\n",
    "    @tool # Or @tool(name=\"get_current_python_version\")\n",
    "    def get_python_version() -> str:\n",
    "        \"\"\"Useful for questions regarding the version of Python currently used.\"\"\"\n",
    "        return python_version() # Uses the imported python_version function\n",
    "    \n",
    "    # Invoking the custom function tool (if it takes no arguments):\n",
    "    # version_info = get_python_version.invoke({})\n",
    "    ```\n",
    "\n",
    "### Conceptual Understanding\n",
    "* **Standardizing Functionality via Tool Abstraction**\n",
    "    1.  **Why is this concept important?** LangChain's tool abstraction provides a uniform interface for an LLM agent to interact with a wide array of functionalities—whether it's retrieving data, calling an external API, or executing custom Python code. This standardization, achieved through classes like `Tool`, `StructuredTool`, and helpers like `create_retriever_tool` or the `@tool` decorator, means the agent can rely on a consistent structure (name, description, input schema) without needing to understand the specific implementation of each underlying function.\n",
    "    2.  **Connection to real‑world tasks, problems, or applications?** In a practical data science scenario, an agent might need to access a SQL database, fetch current stock prices via an API, and run a custom statistical analysis script. By wrapping each of these diverse operations as a LangChain tool, the agent can orchestrate them effectively, choosing the right tool based on the user's goal. This promotes modularity and simplifies the construction of complex, multi-capability AI systems.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** A deeper understanding can be gained by studying API design principles (like RESTful services), the role of function signatures and type hinting in Python for clarity, and the general software engineering concept of interfaces or abstract base classes. Additionally, learning how LLMs perform \"function calling\" or \"tool use\" based on provided schemas and descriptions is highly relevant.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Imagine you have a proprietary Python function that performs complex image analysis and returns a textual description; how would you make this capability available to a LangChain agent for inclusion in automated image-based reporting? Provide a one‑sentence explanation.\n",
    "    * *Answer:* I would decorate the image analysis Python function with `@tool`, providing a clear name like \"describe_image_content\" and a detailed docstring explaining its function (e.g., \"Analyzes an image from a given path/URL and returns a textual description of its content\"), so the LangChain agent can use it for automated reporting.\n",
    "2.  **Teaching:** How would you explain to a junior data scientist the main advantage of using `create_retriever_tool` versus manually writing a Python function with the `@tool` decorator to query a vector database within LangChain? Keep the answer under two sentences.\n",
    "    * *Answer:* `create_retriever_tool` is a specialized, convenient helper that quickly adapts an existing LangChain retriever into a standardized tool, automatically setting up an appropriate input schema for queries. While using `@tool` on a custom function offers great flexibility, you'd have to manually implement the retrieval logic and define the input/output handling if you were to build a retriever interface from scratch this way.\n",
    "\n",
    "# LangChain hub\n",
    "\n",
    "### Summary\n",
    "This lesson outlines the preparatory steps for creating a LangChain agent, emphasizing the use of **LangChain Hub** to acquire pre-defined prompt templates. After installing the `langchain-hub` library, the lesson demonstrates how to `pull` a specific agent prompt (e.g., `\"hwchase17/openai-tools-agent\"`), which includes crucial elements like placeholders for `input`, optional `chat_history`, and the essential `agent_scratchpad` for iterative reasoning, complementing the already prepared list of tools and chat model.\n",
    "\n",
    "### Highlights\n",
    "* **LangChain Hub for Prompts**: LangChain Hub serves as a valuable repository for pre-designed prompt templates. You can easily fetch these templates using `hub.pull(\"template_name\")`, like `\"hwchase17/openai-tools-agent\"`, which provides a robust starting point for agent development, saving time and incorporating best practices.\n",
    "* **Key Agent Prompt Components**: The agent prompt template pulled from the Hub (e.g., `\"hwchase17/openai-tools-agent\"`) typically includes placeholders for user `input`, an optional `chat_history` for conversational memory, and a critical `agent_scratchpad`. This scratchpad is where the agent logs its intermediate steps, tool invocations, and observations, which is fundamental for its reasoning process.\n",
    "* **Inspecting Templates with `.pretty_print()`**: Complex prompt templates fetched from the Hub can be challenging to decipher directly. The `.pretty_print()` method provides a formatted, human-readable output of the template's message structure, clarifying the sequence of system messages, human messages, and placeholders.\n",
    "* **Core Components for an Agent**: The lesson reinforces the essential building blocks required to construct an agent:\n",
    "    * A **list of tools** (e.g., Wikipedia tool, a custom data retriever, a Python version checker).\n",
    "    * A **chat model** (e.g., `ChatOpenAI`).\n",
    "    * A specialized **prompt template** suitable for agentic behavior, which can be sourced from LangChain Hub.\n",
    "* **Optional Chat History**: The demonstrated prompt template (`\"hwchase17/openai-tools-agent\"`) includes an input variable for `chat_history` that is marked as optional. This allows developers to use the same prompt structure for agents that are stateless or for those that need to maintain conversational context, offering flexibility in agent design.\n",
    "\n",
    "---\n",
    "### Code Examples\n",
    "The lesson mentions several key code snippets for setting up and using LangChain Hub:\n",
    "* **Installation**:\n",
    "    ```bash\n",
    "    pip install langchain-hub\n",
    "    ```\n",
    "* **Pulling a prompt template from LangChain Hub**:\n",
    "    ```python\n",
    "    from langchain_core import hub\n",
    "\n",
    "    # The transcript refers to the template as \"Harrison Chase, nicknamed H.W. Chase 17, followed by open AI tools agent\"\n",
    "    # This typically translates to the path \"hwchase17/openai-tools-agent\" in LangChain Hub.\n",
    "    chat_prompt_template = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "    ```\n",
    "* **Inspecting the prompt template**:\n",
    "    ```python\n",
    "    chat_prompt_template.pretty_print()\n",
    "    ```\n",
    "\n",
    "---\n",
    "### Conceptual Understanding\n",
    "* **The Role of `agent_scratchpad` in Agent Prompts**\n",
    "    1.  **Why is this concept important?** The `agent_scratchpad` is a dynamic placeholder within an agent's prompt where the agent records its internal reasoning process. This includes its thoughts on how to proceed, which tool it selects, the input for that tool, and the resulting observation. This \"internal monologue\" is crucial for the LLM to iteratively refine its approach and make decisions towards solving the given task.\n",
    "    2.  **Connection to real‑world tasks, problems, or applications?** For a data science agent tasked with creating a market analysis report, the `agent_scratchpad` might log: \"Thought: I need to fetch current stock prices. Action: use `StockPriceTool` for AAPL. Observation: Price is $150. Thought: Next, I need competitor data. Action: use `CompetitorInfoTool` for tech sector.\" This step-by-step logging makes the agent's process traceable and helps it build complex outputs.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** To fully grasp the utility of the `agent_scratchpad`, it's beneficial to study prompting frameworks like **ReAct (Reason + Act)** and **Chain-of-Thought (CoT)**. These frameworks explicitly detail how an LLM can break down problems into thought-action-observation sequences, which are then typically formatted into the `agent_scratchpad`. Understanding LLM tool use mechanisms is also key.\n",
    "\n",
    "---\n",
    "### Reflective Questions\n",
    "1.  **Application:** If you were building an agent to automate the process of debugging failing unit tests in a software project, why would using a pre-defined agent prompt from LangChain Hub featuring an `agent_scratchpad` be particularly effective?\n",
    "    * *Answer:* A pre-defined prompt with an `agent_scratchpad` would allow the debugging agent to log its sequence of actions (e.g., \"running test X,\" \"inspecting error log for test X,\" \"hypothesizing cause Y\") and observations, making its troubleshooting process transparent and enabling it to systematically narrow down the root cause of failures.\n",
    "2.  **Teaching:** How would you explain the purpose of the `agent_scratchpad` input variable in an agent's prompt template to a colleague who is new to LangChain agents? Keep the answer under two sentences.\n",
    "    * *Answer:* The `agent_scratchpad` is like the agent's working notes or internal monologue; it's where the agent writes down what it's thinking, which tool it's about to use, and what happens after using it, helping it to plan its next steps effectively to solve a problem.\n",
    "\n",
    "# Creating a tool calling agent and an agent executor\n",
    "\n",
    "### Summary\n",
    "This lesson guides through the creation and operation of a LangChain agent using previously assembled components: a list of tools, a chat model, and a prompt template. It introduces the `create_tool_calling_agent` function to define the agent's reasoning logic and the `AgentExecutor` class to run the agent, execute its chosen tools, and manage the interaction flow. By utilizing `verbose=True` and `return_intermediate_steps=True`, the lesson demonstrates how to observe the agent's step-by-step decision-making and tool usage for both simple and complex multi-tool queries, offering insights into its operational mechanics.\n",
    "\n",
    "### Highlights\n",
    "* **Agent Creation with `create_tool_calling_agent`**: An agent, which embodies the decision-making logic, is instantiated using the `create_tool_calling_agent` function. This function binds the language model (`llm`), the available `tools`, and the guiding `prompt` template together, enabling the LLM to determine the appropriate tool and input based on the user's query.\n",
    "* **`AgentExecutor` for Operational Control**: The `AgentExecutor` class is crucial for the practical execution of an agent. It takes the created `agent` and the `tools` list, and then manages the runtime loop: invoking the agent for an action, executing the chosen tool, retrieving the observation, and feeding this back to the agent until a final response is achieved.\n",
    "* **Enhanced Transparency with `verbose=True`**: Setting the `verbose=True` parameter in the `AgentExecutor` provides detailed console logs of the agent's execution path. This includes the specific tool chosen by the agent at each step, the input provided to that tool, and the resulting output (observation), which is invaluable for debugging and understanding the agent's behavior in data science applications.\n",
    "* **Accessing `intermediate_steps`**: When `return_intermediate_steps=True` is set on the `AgentExecutor`, the dictionary returned by an `invoke` call includes an `intermediate_steps` key. This key holds a list of tuples, where each tuple contains the `AgentAction` (tool called and its input) and the corresponding string observation, allowing for a programmatic review of the agent's process.\n",
    "* **Handling Multi-Step, Multi-Tool Queries**: The agent demonstrated its capability to address complex questions by decomposing them and sequentially invoking multiple tools. For instance, it first used a retriever tool to gather information on programming languages from course material, then made several calls to a Wikipedia tool to find their creators, showcasing its ability to orchestrate different tools to build a comprehensive answer.\n",
    "\n",
    "### Code Examples\n",
    "The transcript describes the following key code snippets for creating and running an agent:\n",
    "* **Imports**:\n",
    "    ```python\n",
    "    from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "    ```\n",
    "* **Creating the Agent**:\n",
    "    ```python\n",
    "    # Assuming chat_model, tools_list, and chat_prompt_template are pre-defined\n",
    "    agent = create_tool_calling_agent(\n",
    "        llm=chat_model, \n",
    "        tools=tools_list, \n",
    "        prompt=chat_prompt_template\n",
    "    )\n",
    "    ```\n",
    "* **Creating and Configuring the Agent Executor**:\n",
    "    ```python\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=agent, \n",
    "        tools=tools_list, \n",
    "        verbose=True, \n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "    ```\n",
    "* **Invoking the Agent Executor**:\n",
    "    ```python\n",
    "    response = agent_executor.invoke({\"input\": \"Could you tell me the version of Python I'm currently using?\"})\n",
    "    # The 'response' variable will be a dictionary containing 'input', 'output', and 'intermediate_steps'.\n",
    "    ```\n",
    "\n",
    "### Conceptual Understanding\n",
    "* **Separation of Concerns: Agent vs. AgentExecutor**\n",
    "    1.  **Why is this concept important?** LangChain distinguishes between the agent's \"decision-making\" capability and the \"execution\" mechanism. The `Agent` (created by functions like `create_tool_calling_agent`) is responsible for the reasoning—it determines *what* action to take (e.g., which tool to call with specific input). The `AgentExecutor`, on the other hand, is the runtime component that takes these decisions, actually invokes the tools, gathers their outputs (observations), and manages the iterative loop of interaction back with the `Agent`. This separation enhances modularity and clarity in the system's design.\n",
    "    2.  **How does it connect to real‑world tasks, problems, or applications?** In a data science workflow, an `Agent` might decide, \"I need to fetch the latest sales figures from the database.\" The `AgentExecutor` then handles the practicalities of establishing a database connection, running the SQL query, and managing potential errors, before passing the retrieved data back to the `Agent`. The `Agent` can then decide on the next step, such as \"Now I need to plot this data using the plotting tool.\" This allows the core reasoning logic to remain independent of specific execution environments or error-handling strategies.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Understanding software design patterns like the **Strategy pattern** or **Controller pattern** can provide analogies for this separation. For LLM-specific context, studying tool use prompting techniques (e.g., ReAct, where LLMs generate explicit thought/action steps) helps clarify the kind of structured output the `Agent` component is designed to produce, which the `AgentExecutor` then consumes and acts upon.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** If you were developing a data science assistant to automate aspects of a machine learning pipeline (e.g., data preprocessing, model training, evaluation), how would the `return_intermediate_steps=True` feature of the `AgentExecutor` be invaluable for auditing and reproducibility?\n",
    "    * *Answer:* The `return_intermediate_steps=True` feature would be invaluable by providing a detailed log of each specific tool used (e.g., `data_cleaning_tool` with parameters, `model_training_tool` with chosen algorithm) and its outcome, allowing for a complete audit trail of the ML pipeline's execution, which is crucial for reproducibility and debugging.\n",
    "2.  **Teaching:** How would you explain the difference in purpose between the `agent` object (created by `create_tool_calling_agent`) and the `agent_executor` object to a colleague new to LangChain agents? Keep the answer under two sentences.\n",
    "    * *Answer:* The `agent` is like the strategic planner or \"brain\" that decides which tool to use and what to do next to answer a question. The `agent_executor` is the \"engine\" or \"hands\" that takes those decisions, actually runs the chosen tools, and manages the overall process until the final answer is ready.\n",
    "\n",
    "# AgentAction and AgentFinish\n",
    "\n",
    "### Summary\n",
    "This lesson demonstrates the practical steps to create and utilize a LangChain agent by combining previously prepared tools, a chat model, and a prompt template. It introduces the `create_tool_calling_agent` function for agent creation and the `AgentExecutor` class for running the agent, highlighting how `verbose=True` and `return_intermediate_steps=True` reveal the agent's decision-making process and tool usage when handling both simple and complex queries.\n",
    "\n",
    "### Highlights\n",
    "* **Agent Creation with `create_tool_calling_agent`**: An agent is constructed using the `create_tool_calling_agent` function, which requires the language model (`llm`), the `tools` the agent can use, and the `prompt` template that guides its reasoning. This function encapsulates the logic for an LLM to decide which tool to call based on the input and prompt.\n",
    "* **`AgentExecutor` for Running Agents**: The `AgentExecutor` class is responsible for taking an agent and a list of tools, and then actually executing the sequence of operations. It invokes the agent to get an action, runs the chosen tool, gets an observation, and feeds this back to the agent until a final answer is produced.\n",
    "* **Verbose Output for Transparency**: Setting `verbose=True` in the `AgentExecutor` provides detailed logs of the agent's execution chain. This includes which tool the agent decides to call, the input to that tool, and the observation received, offering crucial insights into the agent's reasoning process for data science debugging and development.\n",
    "* **Returning Intermediate Steps**: By setting `return_intermediate_steps=True` in the `AgentExecutor`, the output of an invocation includes not just the final `input` and `output`, but also a list of `intermediate_steps`. Each step is a tuple containing the `AgentAction` (tool called, tool input) and the corresponding observation (tool output), vital for analyzing the agent's trajectory.\n",
    "* **Multi-Tool Execution for Complex Queries**: The lesson showcases the agent's ability to handle complex, multi-step queries by sequentially invoking different tools. For example, it first used a retriever tool to find relevant course information and then made multiple calls to a Wikipedia tool to gather details about creators of programming languages, demonstrating sophisticated problem decomposition.\n",
    "\n",
    "### Code Examples\n",
    "The transcript describes the following key code snippets for creating and running an agent:\n",
    "* **Imports**:\n",
    "    ```python\n",
    "    from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "    ```\n",
    "* **Creating the Agent**:\n",
    "    ```python\n",
    "    # Assuming chat_model, tools_list, and chat_prompt_template are pre-defined\n",
    "    agent = create_tool_calling_agent(\n",
    "        llm=chat_model, \n",
    "        tools=tools_list, \n",
    "        prompt=chat_prompt_template\n",
    "    )\n",
    "    ```\n",
    "* **Creating and Configuring the Agent Executor**:\n",
    "    ```python\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=agent, \n",
    "        tools=tools_list, \n",
    "        verbose=True, \n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "    ```\n",
    "* **Invoking the Agent Executor**:\n",
    "    ```python\n",
    "    response = agent_executor.invoke({\"input\": \"Your question here\"})\n",
    "    # The 'response' variable will be a dictionary containing 'input', 'output', and 'intermediate_steps'.\n",
    "    ```\n",
    "\n",
    "### Conceptual Understanding\n",
    "* **Separation of Concerns: Agent vs. AgentExecutor**\n",
    "    1.  **Why is this concept important?** LangChain separates the agent's \"decision-making\" logic from the \"execution\" logic. The `Agent` (created by functions like `create_tool_calling_agent`) embodies the reasoning part—it decides *what* action to take next (which tool to call with what input). The `AgentExecutor` is the runtime environment that takes these decisions, actually calls the tools, gets results, and manages the loop of interaction with the `Agent`. This separation makes the system modular and easier to manage.\n",
    "    2.  **How does it connect to real‑world tasks, problems, or applications?** In a complex data analysis task, the `Agent` might decide \"I need to query the sales database for Q1 data.\" The `AgentExecutor` then handles the actual database connection, query execution, and error handling, passing the raw data back to the `Agent` which then decides the next analytical step. This allows different execution environments or strategies without changing the core agent logic.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Understanding design patterns like Strategy or Controller patterns can be helpful. Also, studying the typical LLM prompting techniques for tool use (like ReAct, where the LLM outputs thoughts and actions) clarifies what the `Agent` component is primarily responsible for generating. The `AgentExecutor` then acts on these structured outputs.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** If you were building a data science assistant to automate parts of an exploratory data analysis (EDA) workflow (e.g., loading data, generating summary statistics, creating basic plots), how would the `return_intermediate_steps=True` feature of the `AgentExecutor` be useful during development and for user understanding?\n",
    "    * *Answer:* `return_intermediate_steps=True` would be useful by allowing developers to inspect each step the EDA agent takes (e.g., which data loading tool was called, what statistics were requested, which plotting function was used and with what data), making debugging easier and providing transparency to the user about how the EDA results were generated.\n",
    "2.  **Teaching:** How would you explain the difference in purpose between the `agent` object (created by `create_tool_calling_agent`) and the `agent_executor` object to a colleague new to LangChain agents? Keep the answer under two sentences.\n",
    "    * *Answer:* The `agent` is like the brain that decides *what* to do next (e.g., \"I should use the Wikipedia tool to look up X\"). The `agent_executor` is like the hands that actually *do* it by calling the tool the agent picked, getting the result, and then reporting back to the agent for the next decision.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
